{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8c94d39-4d8d-4a46-97b2-b74d7776a76d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2979134322.py, line 31)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31menvironment)\u001b[39m\n               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# Make printing nicer \n",
    "pd.set_option('display.width', 120) \n",
    "pd.set_option('display.max_columns', 10) \n",
    "# ============================= \n",
    "# 1) SOURCE A: Read from WEB (UCI) \n",
    "# ============================= \n",
    "# UCI Iris CSV with header (commonly mirrored). If blocked, you can try seaborn's github mirror. \n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\" \n",
    "iris_web = pd.read_csv(url) \n",
    "print(\"=== WEB READ: First 5 rows ===\") \n",
    "print(iris_web.head(), \"\\n\") \n",
    "# Standardize column names to the common textbook form (optional) \n",
    "# seaborn schema is: sepal_length, sepal_width, petal_length, petal_width, species \n",
    "iris_web = iris_web.rename(columns={ \n",
    "'sepal_length':'sepal_length', \n",
    "'sepal_width':'sepal_width', \n",
    "'petal_length':'petal_length', \n",
    "'petal_width':'petal_width', \n",
    "'species':'species' \n",
    "}) \n",
    "# ============================= \n",
    "# 2) Prepare local TEXT & EXCEL files (for the experiment) \n",
    "#    (This creates files once, so reading from text/excel works on any machine.) \n",
    "# ============================= \n",
    "csv_path = \"iris_text.csv\"     # text/CSV \n",
    "tsv_path = \"iris_text.tsv\"     # text/TSV \n",
    "xlsx_path = \"iris_excel.xlsx\"  # Excel \n",
    "# Create local files from the web dataframe (only if saving is allowed in your \n",
    "environment) \n",
    "iris_web.to_csv(csv_path, index=False) \n",
    "iris_web.to_csv(tsv_path, sep=\"\\t\", index=False) \n",
    "with pd.ExcelWriter(xlsx_path) as writer: \n",
    "iris_web.to_excel(writer, sheet_name=\"iris\", index=False) \n",
    "# ============================= \n",
    "# 3) SOURCE B: Read from TEXT (CSV/TSV) \n",
    "# ============================= \n",
    "iris_csv = pd.read_csv(csv_path) \n",
    "iris_tsv = pd.read_csv(tsv_path, sep=\"\\t\") \n",
    "print(\"=== TEXT/CSV READ: shape ===\", iris_csv.shape) \n",
    "print(\"=== TEXT/TSV READ: shape ===\", iris_tsv.shape, \"\\n\") \n",
    "# ============================= \n",
    "# 4) SOURCE C: Read from EXCEL \n",
    "# ============================= \n",
    "iris_excel = pd.read_excel(xlsx_path, sheet_name=\"iris\") \n",
    "print(\"=== EXCEL READ: First 3 rows ===\") \n",
    "print(iris_excel.head(3), \"\\n\") \n",
    "# ============================= \n",
    "# 5) Choose a working dataframe for analytics \n",
    "#    (Use the one read from web; others are identical after our save/load.) \n",
    "# ============================= \n",
    "df = iris_web.copy() \n",
    "# Ensure dtype sanity \n",
    "print(\"=== INFO ===\") \n",
    "print(df.info(), \"\\n\") \n",
    "print(\"=== DTYPE CHECK ===\") \n",
    "print(df.dtypes, \"\\n\") \n",
    "# ============================= \n",
    "# 6) DESCRIPTIVE ANALYTICS \n",
    "# ============================= \n",
    "# a) Overall descriptive stats (numeric) \n",
    "print(\"=== DESCRIBE (numeric) ===\") \n",
    "print(df.describe(), \"\\n\") \n",
    "# b) Check missing values \n",
    "print(\"=== MISSING VALUES BY COLUMN ===\") \n",
    "print(df.isna().sum(), \"\\n\") \n",
    "# c) Species distribution (categorical) \n",
    "print(\"=== SPECIES VALUE COUNTS ===\") \n",
    "print(df['species'].value_counts(), \"\\n\") \n",
    "# d) Grouped summaries by species (mean, std, min, max) \n",
    "group_summary = df.groupby('species').agg({ \n",
    "'sepal_length': ['mean', 'std', 'min', 'max'], \n",
    "'sepal_width':  ['mean', 'std', 'min', 'max'], \n",
    "'petal_length': ['mean', 'std', 'min', 'max'], \n",
    "'petal_width':  ['mean', 'std', 'min', 'max'], \n",
    "}) \n",
    "print(\"=== GROUPED SUMMARY BY SPECIES ===\") \n",
    "print(group_summary, \"\\n\") \n",
    "# e) Correlation matrix \n",
    "print(\"=== CORRELATION MATRIX (numeric only) ===\") \n",
    "print(df.corr(numeric_only=True), \"\\n\") \n",
    "# ============================= \n",
    "# 7) OPTIONAL: Quick percentiles and skew/kurtosis \n",
    "# ============================= \n",
    "q_summary = \n",
    "df[['sepal_length','sepal_width','petal_length','petal_width']].quantile([0.25, 0.5, 0.75]) \n",
    "print(\"=== QUARTILES (0.25, 0.5, 0.75) ===\") \n",
    "print(q_summary, \"\\n\") \n",
    "print(\"=== SKEWNESS ===\") \n",
    "print(df[['sepal_length','sepal_width','petal_length','petal_width']].skew(), \"\\n\") \n",
    "print(\"=== KURTOSIS ===\") \n",
    "print(df[['sepal_length','sepal_width','petal_length','petal_width']].kurtosis(), \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f740a2-d1f3-4ac7-8cf5-f3de625c2b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
